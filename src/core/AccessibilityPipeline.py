import os
import json
import datetime
import logging
import tempfile
import subprocess
import sys
import shutil
from pathlib import Path
from typing import Optional, Dict, List, Any, Union
from datetime import timedelta

import whisper
from pydub import AudioSegment
from vertexai.generative_models import GenerativeModel
from dotenv import load_dotenv

sys.path.append("src/core")
from video_analyzer import VideoAnalyzer, YouTubeVideoManager
from audio_processor import AudioProcessor, VoiceSynthesizer
from speech_processor import SpeechProcessor
from text_processor import TextProcessor

load_dotenv()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AccessibilityPipeline:
    """
    Pipeline unificado para procesamiento de accesibilidad de videos.
    Implementa est√°ndares UNE 153010 (subt√≠tulos) y UNE 153020 (audiodescripci√≥n).
    """
    def __init__(self, source: str, output_dir: Optional[str] = None):

        # M√°xima duraci√≥n permitida (100 minutos en segundos)
        self.MAX_DURATION = 6000

        self.source = source
        self.output_dir = Path(output_dir) if output_dir else Path("output")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.temp_dir = Path(tempfile.mkdtemp())
        
        # Inicializar Whisper con manejo de errores
        try:
            self.whisper_model = whisper.load_model("base")
            logger.info("Whisper initialized successfully")
        except ImportError as e:
            logger.error("Error importing Whisper. Make sure openai-whisper is installed correctly")
            logger.error("Try: pip install openai-whisper setuptools-rust")
            raise ImportError("Failed to import Whisper. Please install openai-whisper") from e
        except Exception as e:
            logger.error(f"Error initializing Whisper: {str(e)}")
            raise
        
        # Verificar ffmpeg
        if not self._check_ffmpeg():
            raise RuntimeError("ffmpeg not found. Please install ffmpeg and add it to PATH")
        
        try:
            self.text_processor = TextProcessor()
            logger.info("TextProcessor initialized successfully")
        except Exception as e:
            logger.error(f"Error initializing TextProcessor: {str(e)}")
            raise
        
        self.voice_synthesizer = VoiceSynthesizer()
        
        # Inicializar modelo de VertexAI
        self._init_vertex_ai()
        
        # Inicializar componentes
        self.video_analyzer = VideoAnalyzer(model=self.vertex_model)
        self.audio_processor = AudioProcessor(model=self.vertex_model)
        self.speech_processor = SpeechProcessor(model=self.vertex_model)
        
    def _init_vertex_ai(self):
        """Inicializa el modelo de VertexAI."""
        try:
            import vertexai
            from vertexai.generative_models import GenerativeModel
            
            project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
            location = os.getenv("GOOGLE_CLOUD_REGION", "us-central1")
            vertexai.init(project=project_id, location=location)
            
            self.vertex_model = GenerativeModel("gemini-pro")
        except Exception as e:
            logger.error(f"Error inicializando VertexAI: {e}")
            raise
    
    def _check_ffmpeg(self) -> bool:
        """Verifica si ffmpeg est√° instalado y disponible."""
        try:
            subprocess.run(['ffmpeg', '-version'], capture_output=True)
            return True
        except FileNotFoundError:
            return False
    
    def _get_video(self) -> str:
        """
        Obtiene el video desde la fuente (URL o archivo local).
        
        Returns:
            str: Ruta al archivo de video
        """
        if self.source.startswith(('http://', 'https://', 'www.', 'youtube.com', 'youtu.be')):
            # Es una URL de YouTube
            logger.info(f"Descargando video de YouTube: {self.source}")
            yt_manager = YouTubeVideoManager(youtube_url=self.source)
            video_path = yt_manager.download_video(output_dir=self.temp_dir)
            return video_path
        elif os.path.isfile(self.source):
            # Es un archivo local
            logger.info(f"Usando archivo de video local: {self.source}")
            return self.source
        else:
            raise ValueError(f"Fuente no v√°lida: {self.source}")
        
    def _get_video_duration(self, video_path: str) -> float:
        """
        Obtiene la duraci√≥n del video en segundos.
        
        Args:
            video_path (str): Ruta al archivo de video
            
        Returns:
            float: Duraci√≥n en segundos
        """
        try:
            result = subprocess.run(
                ['ffprobe', '-v', 'error', '-show_entries', 'format=duration', 
                '-of', 'default=noprint_wrappers=1:nokey=1', video_path],
                capture_output=True,
                text=True
            )
            duration = float(result.stdout.strip())
            logger.info(f"Duraci√≥n del video: {duration:.2f} segundos")
            return duration
        except Exception as e:
            logger.error(f"Error al obtener duraci√≥n del video: {e}")
            raise
    
    def process_video(self) -> Dict[str, str]:
        """
        Processes the entire video generating subtitles and audio description.
        
        Returns:
            Dict with paths to the generated files
        """
        try:
            # Get video
            video_path = self._get_video()
            
            # Verify duration
            duration = self._get_video_duration(video_path)
            if duration > self.MAX_DURATION:
                raise ValueError(f"Video exceeds maximum duration of {self.MAX_DURATION/60} minutes")
            
            # Process video
            logger.info(f"Starting video processing: {self.source}")
            
            # Analyze the entire video first for better context
            logger.info("Analyzing video scenes...")
            scenes = self.video_analyzer.detect_scenes(video_path)
            logger.info(f"{len(scenes)} scenes detected in the video")
            
            # Generate subtitles according to UNE 153010
            logger.info("Generating subtitles according to UNE 153010 standard...")
            srt_path, subtitles_data = self._generate_subtitles(video_path)
            logger.info(f"Subtitles generated and saved to: {srt_path}")
            
            # Verify subtitles file
            if not os.path.exists(srt_path):
                logger.error(f"Subtitle file not created: {srt_path}")
                raise FileNotFoundError(f"Failed to create subtitle file at {srt_path}")
            
            # Generate complete script minute by minute
            logger.info("Generating complete minute-by-minute script...")
            full_script_path = self._generate_full_script(video_path, subtitles_data, scenes)
            logger.info(f"Complete script generated and saved to: {full_script_path}")
            
            # Generate audio description from the complete script
            logger.info("Generating audio description from the complete script...")
            audio_desc_path, audio_desc_script = self._generate_audio_description_from_script(full_script_path, video_path)
            logger.info(f"Audio description generated and saved to: {audio_desc_path}")
            
            # Verify audio description file
            if not os.path.exists(audio_desc_path) or os.path.getsize(audio_desc_path) < 1000:
                logger.error(f"Audio description file is empty or invalid: {audio_desc_path}")
                raise ValueError(f"Audio description generation failed or produced an empty file")
            
            # Extract original audio from video
            orig_audio_path = self._extract_audio_from_video(video_path)
            logger.info(f"Original audio extracted and saved to: {orig_audio_path}")
            
            # Generate final video with audio description and subtitles
            logger.info("Generating final video with complete accessibility...")
            final_video = self._merge_audio_description_fixed(video_path, audio_desc_path, srt_path)
            logger.info(f"Final video generated and saved to: {final_video}")
            
            # Verify final video
            if not os.path.exists(final_video):
                logger.error(f"Final video was not created: {final_video}")
                raise FileNotFoundError(f"Failed to create final video at {final_video}")
            
            # Prepare files for download
            output_files = self._prepare_output_files(
                video_path, 
                srt_path,
                audio_desc_path,
                audio_desc_script,
                full_script_path,
                final_video,
                orig_audio_path
            )
            
            logger.info("Processing completed successfully!")
            return output_files
            
        except Exception as e:
            logger.error(f"Error in processing: {e}")
            # Try to salvage any generated files
            output_files = {}
            
            # Check if partial files were created and include them in the output
            possible_paths = {
                'subtitles': self.output_dir / "subtitles_une153010.srt",
                'full_script': self.output_dir / "full_script_minute_by_minute.txt",
                'audio_description_script': self.output_dir / "audio_description_script.txt",
                'audio_description': self.output_dir / "audio_description.mp3",
                'original_audio': self.output_dir / "original_audio.mp3"
            }
            
            for key, path in possible_paths.items():
                if os.path.exists(path):
                    output_files[key] = str(path)
                    logger.info(f"Salvaged partial file: {key} at {path}")
            
            if output_files:
                logger.info(f"Returning {len(output_files)} partial files despite processing error")
                return output_files
            else:
                raise

    def _extract_audio_from_video(self, video_path: str) -> str:
        """
        Extrae el audio original del video en formato MP3.
        
        Args:
            video_path (str): Ruta al archivo de video
            
        Returns:
            str: Ruta al archivo de audio extra√≠do
        """
        logger.info("Extrayendo audio original del video...")
        output_path = self.output_dir / "original_audio.mp3"
        
        try:
            subprocess.run([
                'ffmpeg', '-y',
                '-i', video_path,
                '-vn',  # Sin video
                '-acodec', 'libmp3lame',  # Usar codec MP3
                '-q:a', '2',  # Alta calidad
                str(output_path)
            ], check=True, capture_output=True)
            
            return str(output_path)
        except subprocess.CalledProcessError as e:
            logger.error(f"Error al extraer audio del video: {e.stderr.decode()}")
            raise RuntimeError(f"Error al extraer audio: {e}")

    def _generate_subtitles(self, video_path: str) -> tuple[str, List[Dict]]:
        """
        Genera subt√≠tulos seg√∫n UNE 153010 y los guarda en un archivo .srt.
        
        Returns:
            Tuple con la ruta al archivo .srt generado y los datos de subt√≠tulos procesados.
        """
        logger.info("Generando subt√≠tulos...")
        
        # Transcribir audio
        result = self.whisper_model.transcribe(video_path)
        
        # Procesar transcripci√≥n para formato SRT
        segments = result["segments"]
        srt_content = []
        subtitles_data = []
        
        for i, segment in enumerate(segments, 1):
            # Formatear tiempos
            start = self._format_timecode(segment['start'])
            end = self._format_timecode(segment['end'])
            
            # Formatear texto seg√∫n UNE 153010
            formatted_subtitles = self.text_processor.format_subtitles(segment['text'])
            
            for j, subtitle in enumerate(formatted_subtitles):
                subtitle_index = i * 10 + j  # Evita √≠ndices duplicados
                srt_content.extend([
                    str(subtitle_index),
                    f"{start} --> {end}",
                    subtitle['text'],
                    ""
                ])
                
                # Guardar datos para uso posterior
                subtitles_data.append({
                    'index': subtitle_index,
                    'start': segment['start'],
                    'end': segment['end'],
                    'text': subtitle['text']
                })
        
        # Guardar archivo SRT seg√∫n la norma UNE 153010
        srt_path = self.output_dir / "subtitles_une153010.srt"
        with open(srt_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(srt_content))
            
        return str(srt_path), subtitles_data

    def _format_timecode(self, seconds: float) -> str:
        """Convierte segundos a formato de tiempo SRT (HH:MM:SS,mmm)"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        seconds = seconds % 60
        milliseconds = int((seconds - int(seconds)) * 1000)
        
        return f"{hours:02d}:{minutes:02d}:{int(seconds):02d},{milliseconds:03d}"

    def _generate_full_script(self, video_path, subtitles, scenes):
        """
        Genera un guion completo del video combinando transcripciones y descripciones,
        organizando el contenido minuto a minuto.
        
        Args:
            video_path (str): Ruta al video
            subtitles (list): Lista de subt√≠tulos procesados
            scenes (list): Lista de escenas detectadas
            
        Returns:
            str: Ruta al archivo de guion generado
        """
        logger.info("Generando guion completo minuto a minuto...")
        
        # Obtener duraci√≥n total del video
        total_duration = self._get_video_duration(video_path)
        total_minutes = int(total_duration / 60) + 1
        
        # Preparar datos para segmentaci√≥n por minutos
        minute_segments = {}
        
        # Organizar subt√≠tulos por minutos
        for sub in subtitles:
            minute = int(sub['start'] / 60)
            if minute not in minute_segments:
                minute_segments[minute] = {"subtitles": [], "scenes": []}
            minute_segments[minute]["subtitles"].append(sub)
        
        # Organizar escenas por minutos
        for scene in scenes:
            start_minute = int(scene['start_time'] / 60)
            end_minute = int(scene['end_time'] / 60)
            
            for minute in range(start_minute, end_minute + 1):
                if minute not in minute_segments:
                    minute_segments[minute] = {"subtitles": [], "scenes": []}
                minute_segments[minute]["scenes"].append(scene)
        
        # Generar guion completo con IA
        prompt = f"""
        Act√∫a como un guionista profesional especializado en audiodescripci√≥n seg√∫n la norma UNE 153020.
        
        Crea un guion completo MINUTO A MINUTO del siguiente video con duraci√≥n total de {total_minutes} minutos.
        Genera un guion con subt√≠tulos y descripciones de escenas de forma profesional. 
        Evita lenguaje expl√≠cito o inapropiado, y usa un estilo neutro y objetivo.
        
        Para cada minuto, incluye una secci√≥n claramente identificada (MINUTO 1, MINUTO 2, etc.) y detalla TODO lo que sucede
        en ese segmento de tiempo, integrando di√°logos y elementos visuales.
        
        En cada silencio o pausa debe haber una audiodescripci√≥n. Aseg√∫rate de que las descripciones:
        - Sean breves y concisas
        - Se integren naturalmente entre los di√°logos
        - Describan elementos visuales relevantes
        - Sean objetivas y no interpreten intenciones
        - No repitan informaci√≥n que ya se deduce del audio
        
        CONTENIDO DEL VIDEO POR MINUTOS:
        """
        
        # A√±adir contenido organizado por minutos
        for minute in range(total_minutes):
            prompt += f"\n\nMINUTO {minute+1}:\n"
            
            if minute in minute_segments:
                data = minute_segments[minute]
                
                if data["subtitles"]:
                    prompt += "DI√ÅLOGOS:\n"
                    for sub in data["subtitles"]:
                        time_str = f"{sub['start']:.2f}s - {sub['end']:.2f}s"
                        prompt += f"- [{time_str}] {sub['text']}\n"
                
                if data["scenes"]:
                    prompt += "\nCONTENIDO VISUAL:\n"
                    for scene in data["scenes"]:
                        if minute * 60 <= scene['start_time'] <= (minute + 1) * 60:
                            time_str = f"{scene['start_time']:.2f}s - {min(scene['end_time'], (minute + 1) * 60):.2f}s"
                            prompt += f"- [{time_str}] {scene['description']}\n"
            else:
                prompt += "[Sin contenido transcrito para este minuto]\n"
        
        prompt += """
        El guion final debe:
        1. Mantener una estructura clara MINUTO A MINUTO
        2. Integrar di√°logos y descripciones de forma coherente
        3. Incluir acotaciones detalladas sobre lo que se ve en pantalla
        4. Identificar claramente a los personajes cuando hablan,si tienen nombre identificals por su nombre
        5. Seguir el formato profesional de guion cinematogr√°fico
        6. Marcar claramente los tiempos de cada elemento (en segundos)
        7. Aportar contexto visual para cada di√°logo cuando sea necesario
        
        Para la audiodescripci√≥n, respeta todas las normas UNE 153020:
        - Usa lenguaje claro y sencillo adaptado al contenido
        - Evita describir lo obvio
        - No adelantes acontecimientos ni censures informaci√≥n
        - Incluye claramente qu√© momentos son descripciones para distinguirlos de los di√°logos
        """

        # Usar VertexAI para generar el guion
        response = self.vertex_model.generate_content(prompt)
        script = response.text
        
        # Guardar guion completo
        script_path = self.output_dir / "full_script_minute_by_minute.txt"
        with open(script_path, "w", encoding="utf-8") as f:
            f.write(script)
        
        return str(script_path)
    
    def _generate_audio_description_from_script(self, script_path: str, video_path: str) -> tuple[str, str]:
        """
        Generates audio description from the script with "en esta escena" format.
        """
        logger.info("Extracting descriptions from complete script...")
        
        # Read the complete script
        with open(script_path, 'r', encoding='utf-8') as f:
            full_script = f.read()
        
        # Process with AI to extract only the audio description parts
        prompt = """
        Extrae solo las descripciones de audio del siguiente guion completo.  
        Formatea cada descripci√≥n para que comience con "En esta escena",
        seguida de una descripci√≥n clara de lo que est√° sucediendo.  

        Para cada descripci√≥n, incluye:  
        1. El tiempo exacto en segundos (inicio-fin).  
        2. El texto de la descripci√≥n comenzando con "En esta escena".  

        Usa este formato:  
        **[INICIO_FIN] En esta escena DESCRIPCI√ìN**  

        Por ejemplo:  
        **[25.5-30.2] En esta escena el personaje camina lentamente hacia la ventana.**  

        Aseg√∫rate de:  
        - Incluir SOLO las descripciones, no los di√°logos.  
        - Mantener los tiempos exactos del guion original.  
        - Incluir las descripciones m√°s importantes y relevantes.  
        - Siempre comenzar cada descripci√≥n con "En esta escena".  

        **GUION COMPLETO:**  
        """
        prompt += full_script
        
        # Generate audio description script
        response = self.vertex_model.generate_content(prompt)
        descriptions_script = response.text
        
        # Save audio description script
        audiodesc_script_path = self.output_dir / "audio_description_script.txt"
        with open(audiodesc_script_path, 'w', encoding='utf-8') as f:
            f.write(descriptions_script)
        
        logger.info("Generating audio for each description...")
        
        # Parse the script to extract descriptions and times - improved regex
        descriptions = []
        
        import re
        # More flexible regex to catch different timestamp formats
        pattern = r'\[(\d+\.?\d*)-(\d+\.?\d*)\]\s*(.*)'
        
        for line in descriptions_script.split('\n'):
            line = line.strip()
            if not line or line.startswith('#') or line.startswith('MINUTO'):
                continue
                
            # Look for format [start-end] Description
            match = re.match(pattern, line)
            
            if match:
                start_time = float(match.group(1))
                end_time = float(match.group(2))
                description_text = match.group(3)
                
                # Add "En esta escena" prefix if not already present
                if not description_text.lower().startswith("en esta escena"):
                    description_text = "En esta escena " + description_text
                
                descriptions.append({
                    'start': start_time,
                    'end': end_time,
                    'text': description_text
                })
        
        if not descriptions:
            logger.warning("No descriptions found in the script. Using fallback pattern.")
            # Try alternative pattern that might catch timestamps in different formats
            pattern2 = r'.*?(\d+(?:\.\d+)?)\s*-\s*(\d+(?:\.\d+)?)\s*[:\]]\s*(.*)'
            
            for line in descriptions_script.split('\n'):
                line = line.strip()
                if not line:
                    continue
                    
                match = re.match(pattern2, line)
                if match:
                    start_time = float(match.group(1))
                    end_time = float(match.group(2))
                    description_text = match.group(3)
                    
                    # Add "En esta escena" prefix if not already present
                    if not description_text.lower().startswith("en esta escena"):
                        description_text = "En esta escena " + description_text
                    
                    descriptions.append({
                        'start': start_time,
                        'end': end_time,
                        'text': description_text
                    })
        
        if not descriptions:
            logger.warning("Still no descriptions found. Creating default descriptions from script.")
            # Create simple descriptions based on script sections
            minutes = re.findall(r'MINUTO (\d+):', full_script)
            for i, minute in enumerate(minutes):
                start_time = (int(minute) - 1) * 60 + 10  # 10 seconds into each minute
                end_time = start_time + 5  # 5 second duration
                description_text = f"En esta escena contin√∫a el minuto {minute} del video."
                
                descriptions.append({
                    'start': start_time,
                    'end': end_time,
                    'text': description_text
                })
        
        if not descriptions:
            logger.warning("No descriptions could be extracted. Generating a sample description.")
            # Final fallback with hardcoded samples
            descriptions = [
                {
                    'start': 10.0,
                    'end': 15.0,
                    'text': "En esta escena comienza el video."
                },
                {
                    'start': 30.0,
                    'end': 35.0,
                    'text': "En esta escena contin√∫a la acci√≥n principal."
                },
                {
                    'start': 60.0,
                    'end': 65.0,
                    'text': "En esta escena se desarrolla el contenido central."
                }
            ]
        
        logger.info(f"Found {len(descriptions)} descriptions to process")
        
        # Generate an audio file for each description
        audio_segments = []
        
        # Voice options according to UNE 153020
        voice_options = {
            'rate': 1.1,  # Slightly faster to take advantage of short silences
            'pitch': 0.0  # Natural tone
        }
        
        # Create a blank audio of the total video duration
        video_duration = self._get_video_duration(video_path)
        combined_audio = AudioSegment.silent(duration=int(video_duration * 1000))
        
        for i, desc in enumerate(descriptions):
            # Calculate available duration
            available_duration = desc['end'] - desc['start']
            
            if available_duration <= 0:
                logger.warning(f"Invalid duration for description {i}: {available_duration}s. Skipping.")
                continue
            
            # Ensure text starts with "En esta escena"
            description_text = desc['text']
            if not description_text.lower().startswith("en esta escena"):
                description_text = "En esta escena " + description_text
            
            # Adjust text if necessary to fit in available time
            description_text = self.text_processor.format_audio_description(
                description_text,
                max_duration=available_duration
            )
            
            # Temporary file name
            temp_audio_file = self.temp_dir / f"desc_{i}.mp3"
            
            logger.info(f"Generating audio for description {i+1}/{len(descriptions)}: {description_text[:50]}...")
            
            try:
                # Generate audio
                audio_content = self.voice_synthesizer.generate_audio(
                    description_text,
                    rate=voice_options['rate'],
                    pitch=voice_options['pitch']
                )
                
                # Save audio
                with open(temp_audio_file, 'wb') as f:
                    f.write(audio_content)
                
                # Load and position the audio in the combined track
                segment = AudioSegment.from_file(temp_audio_file)
                
                # Calculate position in milliseconds
                position_ms = int(desc['start'] * 1000)
                
                # Add the segment
                combined_audio = combined_audio.overlay(segment, position=position_ms)
                
                # Add to the list of segments
                audio_segments.append({
                    'file': str(temp_audio_file),
                    'start': desc['start'],
                    'end': desc['end'],
                    'text': description_text
                })
                
            except Exception as e:
                logger.error(f"Error processing audio segment {i}: {e}")
        
        if not audio_segments:
            logger.warning("No audio segments were successfully generated. Creating a default audio.")
            # Create a default audio in case all generation fails
            default_text = "En esta escena se desarrolla la acci√≥n principal del video."
            audio_content = self.voice_synthesizer.generate_audio(default_text)
            default_audio_file = self.temp_dir / "default_desc.mp3"
            
            with open(default_audio_file, 'wb') as f:
                f.write(audio_content)
                
            segment = AudioSegment.from_file(default_audio_file)
            combined_audio = combined_audio.overlay(segment, position=5000)  # At 5 seconds
        
        # Save combined audio as MP3
        audio_desc_path = self.output_dir / "audio_description.mp3"
        combined_audio.export(str(audio_desc_path), format="mp3", bitrate="192k")
        
        # Verify the generated file
        if os.path.getsize(str(audio_desc_path)) < 1000:  # Less than 1KB
            logger.error("Generated audio file is too small. Audio generation failed.")
            # Create a default audio file with actual content
            try:
                default_text = "En esta escena comienza el video. La audiodescripci√≥n ayuda a comprender el contenido visual."
                audio_content = self.voice_synthesizer.generate_audio(default_text)
                with open(str(audio_desc_path), 'wb') as f:
                    f.write(audio_content)
                logger.info("Created default audio description as fallback")
            except Exception as e:
                logger.error(f"Failed to create default audio: {e}")
                # Final fallback - create a simple audio file
                default_audio = AudioSegment.silent(duration=1000)  # 1 second
                tone = AudioSegment.from_file(os.path.join(os.path.dirname(__file__), "resources/beep.mp3")) if os.path.exists(os.path.join(os.path.dirname(__file__), "resources/beep.mp3")) else AudioSegment.silent(duration=500)
                default_audio = default_audio.overlay(tone, position=0)
                default_audio.export(str(audio_desc_path), format="mp3", bitrate="192k")
        
        # Improve final audio quality
        enhanced_audio_path = self.output_dir / "audio_description_enhanced.mp3"
        try:
            # Normalize and improve audio quality with FFmpeg
            subprocess.run([
                'ffmpeg', '-y',
                '-i', str(audio_desc_path),
                '-af', 'loudnorm=I=-16:TP=-1.5:LRA=11',  # Normalization for better quality
                '-ar', '48000',  # High sampling frequency
                '-b:a', '192k',  # High bitrate
                str(enhanced_audio_path)
            ], check=True, capture_output=True)
            
            if os.path.exists(str(enhanced_audio_path)) and os.path.getsize(str(enhanced_audio_path)) > 1000:
                return str(enhanced_audio_path), str(audiodesc_script_path)
            else:
                logger.warning("Enhanced audio file is too small. Using original version.")
                return str(audio_desc_path), str(audiodesc_script_path)
        except subprocess.CalledProcessError as e:
            logger.warning(f"Could not improve audio, using original version: {e}")
            return str(audio_desc_path), str(audiodesc_script_path)

    def _merge_audio_description_fixed(self, video_path: str, audio_desc_path: str, srt_path: str) -> str:
        """
        Generates a final video with embedded subtitles and overlaid audio description.

        Args:
            video_path: Path to the original video.
            audio_desc_path: Path to the audio description.
            srt_path: Path to the subtitles file.

        Returns:
            Path to the generated final video.
        """
        logger.info("Generating final video with overlaid audio description and subtitles...")

        output_path = self.output_dir / "video_with_accessibility.mp4"

        # Verify files exist
        for path, name in [(video_path, "Video"), (audio_desc_path, "Audio description"), (srt_path, "Subtitles")]:
            if not os.path.exists(path):
                logger.error(f"{name} not found: {path}")
                raise FileNotFoundError(f"{name} not found at: {path}")
            
            # Also check if files are not empty
            if os.path.getsize(path) < 1000 and name != "Subtitles":  # Subtitles can be small
                logger.error(f"{name} file is too small: {path}")
                raise ValueError(f"{name} file appears to be empty or corrupt: {path}")

        # Escape paths for FFmpeg
        video_path_escaped = str(video_path).replace("'", "'\\''")
        audio_desc_path_escaped = str(audio_desc_path).replace("'", "'\\''")
        srt_path_escaped = str(srt_path).replace("'", "'\\''")

        try:
            # First, check the audio description file can be processed
            logger.info("Checking audio description file...")
            proc = subprocess.run(['ffprobe', '-i', audio_desc_path], 
                                capture_output=True, text=True)
            
            if "Invalid data found" in proc.stderr:
                logger.error(f"Audio description file is corrupt or invalid: {proc.stderr}")
                # Create a simple valid audio file as fallback
                logger.warning("Creating fallback audio description file...")
                temp_audio = self.temp_dir / "fallback_audio.mp3"
                subprocess.run([
                    'ffmpeg', '-y',
                    '-f', 'lavfi',  # Use libavfilter
                    '-i', 'anullsrc=r=44100:cl=stereo',  # Generate silent audio
                    '-t', '5',  # 5 seconds duration
                    '-q:a', '0',  # Best quality
                    '-af', 'volume=0.5',  # Set volume
                    str(temp_audio)
                ], check=True)
                
                audio_desc_path = str(temp_audio)
            
            # Simplified approach: Use a direct two-step process
            # 1. Create a mix of original audio and description
            mixed_audio = self.temp_dir / "mixed_audio.mp3"
            
            # Try different mixing approach - use a filter to lower original audio when description plays
            logger.info("Mixing audio tracks...")
            mix_cmd = [
                'ffmpeg', '-y',
                '-i', video_path,
                '-i', audio_desc_path,
                '-filter_complex', 
                # This filter lowers original audio by 50% and mixes both sources
                '[0:a]volume=0.5[a1];[1:a]volume=1.0[a2];[a1][a2]amix=inputs=2:duration=longest',
                '-c:a', 'libmp3lame',
                '-q:a', '3',
                str(mixed_audio)
            ]
            
            try:
                subprocess.run(mix_cmd, check=True, capture_output=True)
            except subprocess.CalledProcessError as e:
                logger.error(f"Error mixing audio: {e.stderr.decode() if hasattr(e, 'stderr') else str(e)}")
                # Fallback to simpler mixing
                logger.info("Trying simpler audio mixing...")
                subprocess.run([
                    'ffmpeg', '-y',
                    '-i', video_path,
                    '-i', audio_desc_path,
                    '-filter_complex', '[0:a][1:a]amerge=inputs=2[aout]',
                    '-map', '[aout]',
                    '-c:a', 'libmp3lame',
                    str(mixed_audio)
                ], check=True)
            
            # 2. Create final video with mixed audio and subtitles
            logger.info("Creating final video with combined audio and subtitles...")
            subtitle_filter = f"subtitles={srt_path_escaped}:force_style='FontName=Arial,FontSize=24,PrimaryColour=&HFFFFFF,OutlineColour=&H000000,BackColour=&H80000000,BorderStyle=4,Outline=1,Shadow=0'"
            
            try:
                subprocess.run([
                    'ffmpeg', '-y',
                    '-i', video_path,
                    '-i', str(mixed_audio),
                    '-c:v', 'libx264',
                    '-preset', 'medium',
                    '-crf', '20',
                    '-map', '0:v',  # Take video from first input
                    '-map', '1:a',  # Take audio from mixed audio
                    '-vf', subtitle_filter,
                    '-c:a', 'aac',
                    '-b:a', '192k',
                    str(output_path)
                ], check=True, capture_output=True)
            except subprocess.CalledProcessError as e:
                logger.error(f"Error in final video creation: {e.stderr.decode() if hasattr(e, 'stderr') else str(e)}")
                # Try with hardcoded subtitle path
                logger.info("Trying alternative subtitle embedding...")
                try:
                    subprocess.run([
                        'ffmpeg', '-y',
                        '-i', video_path,
                        '-i', str(mixed_audio),
                        '-c:v', 'libx264',
                        '-preset', 'medium',
                        '-crf', '20',
                        '-map', '0:v',  # Take video from first input
                        '-map', '1:a',  # Take audio from mixed audio
                        '-vf', f"subtitles={srt_path_escaped}",
                        '-c:a', 'aac',
                        '-b:a', '192k',
                        str(output_path)
                    ], check=True)
                except subprocess.CalledProcessError as e2:
                    logger.error(f"Alternative subtitle embedding also failed: {e2}")
                    # Final fallback - just combine video with mixed audio, no subtitles
                    logger.warning("Creating video with mixed audio only, no subtitles")
                    subprocess.run([
                        'ffmpeg', '-y',
                        '-i', video_path,
                        '-i', str(mixed_audio),
                        '-c:v', 'copy',
                        '-map', '0:v',
                        '-map', '1:a',
                        '-c:a', 'aac',
                        '-b:a', '192k',
                        str(output_path)
                    ], check=True)
                    
            return str(output_path)
            
        except Exception as e:
            logger.error(f"Error in _merge_audio_description_fixed: {str(e)}")
            # Create a fallback video with just copied original and subtitles
            try:
                logger.warning("Creating fallback video with original audio and subtitles...")
                subtitle_filter = f"subtitles={srt_path_escaped}"
                subprocess.run([
                    'ffmpeg', '-y',
                    '-i', video_path,
                    '-c:v', 'libx264',
                    '-preset', 'fast',
                    '-vf', subtitle_filter,
                    '-c:a', 'copy',
                    str(output_path)
                ], check=True)
                return str(output_path)
            except Exception as e2:
                logger.error(f"Fallback video creation also failed: {str(e2)}")
                raise RuntimeError(f"Could not create accessible video: {str(e)}")


    def _generate_video_without_audio_desc(self, video_path, srt_path_escaped, subtitle_style, output_path):
        """Genera video solo con subt√≠tulos, sin audiodescripci√≥n."""
        try:
            logger.info("Generando video solo con subt√≠tulos (sin audiodescripci√≥n)...")
            result = subprocess.run([
                'ffmpeg', '-y',
                '-i', video_path,
                '-c:v', 'libx264',
                '-crf', '18',
                '-preset', 'medium',
                '-c:a', 'aac',
                '-b:a', '192k',
                '-vf', f"subtitles='{srt_path_escaped}':force_style='{subtitle_style}'",
                '-metadata', 'title="Video con subt√≠tulos seg√∫n UNE 153010"',
                output_path
            ], capture_output=True, text=True)
            
            if result.returncode != 0:
                logger.error(f"Error generando video con subt√≠tulos: {result.stderr}")
                raise RuntimeError("Error al generar video con subt√≠tulos")
                
            logger.info(f"Video con subt√≠tulos generado correctamente: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"Error generando video con subt√≠tulos: {str(e)}")
            raise RuntimeError(f"Error al generar video con subt√≠tulos: {str(e)}")

    def _prepare_output_files(self, 
                            video_path: str,
                            srt_path: str,
                            audio_desc_path: str,
                            audio_desc_script: str,
                            full_script_path: str,
                            final_video_path: str,
                            orig_audio_path: str) -> Dict[str, str]:
        """Prepara y organiza archivos finales."""
        # Copiar archivos a directorio final
        final_paths = {
            'subtitles': srt_path,
            'audio_description': audio_desc_path,
            'audio_description_script': audio_desc_script,
            'full_script': full_script_path,
            'video_with_audio_description': final_video_path,
            'original_audio': orig_audio_path
        }
        
        # Copiar archivos para el video_processor.py
        temp_dir = Path("C:/Users/Administrator/AppData/Local/Temp")
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            # Copiar video
            shutil.copy2(video_path, temp_dir / "video.mp4")
            logger.info(f"Video copiado a {temp_dir / 'video.mp4'}")
            
            # Extraer y copiar audio
            audio_temp = self.temp_dir / "temp_audio.aac"
            subprocess.run([
                'ffmpeg', '-y',
                '-i', video_path,
                '-vn', '-acodec', 'copy',
                str(audio_temp)
            ], check=True)
            shutil.copy2(str(audio_temp), temp_dir / "audio.aac")
            logger.info(f"Audio copiado a {temp_dir / 'audio.aac'}")
            
            # Copiar subt√≠tulos
            shutil.copy2(srt_path, temp_dir / "subtitles.srt")
            logger.info(f"Subt√≠tulos copiados a {temp_dir / 'subtitles.srt'}")
        except Exception as e:
            logger.error(f"Error copiando archivos para video_processor: {e}")
        
        # Generar archivo de metadatos
        metadata = {
            'processed_at': str(datetime.datetime.now()),
            'source': self.source,
            'standards': {
                'subtitles': 'UNE 153010',
                'audio_description': 'UNE 153020'
            },
            'files': final_paths
        }
        
        metadata_path = self.output_dir / 'metadata.json'
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        final_paths['metadata'] = str(metadata_path)
        return final_paths
    def generate_from_script(self, script_path: str) -> dict:
        """
        Genera archivos de accesibilidad partiendo del guion completo.
        """
        logger.info(f"Generando archivos de accesibilidad desde el guion: {script_path}")
        
        if not os.path.isfile(script_path):
            raise FileNotFoundError(f"El archivo de guion no existe: {script_path}")
        
        with open(script_path, 'r', encoding='utf-8') as f:
            script_content = f.read()
        
        subtitles_data, descriptions_data = self._parse_script_content(script_content)
        srt_path = self._generate_srt_from_parsed_data(subtitles_data)
        audio_desc_path = self._generate_audio_from_descriptions(descriptions_data)
        
        video_path = self.source if os.path.isfile(self.source) else input("Introduce la ruta al video original: ")
        if not os.path.isfile(video_path):
            raise FileNotFoundError(f"El archivo de video no existe: {video_path}")
        
        final_video_path = self.merge_audio_description(video_path, audio_desc_path, srt_path)
        
        return {
            'subtitles': srt_path,
            'audio_description': audio_desc_path,
            'final_video': final_video_path
        }


if __name__ == "__main__":
    print("\n===== SISTEMA DE GENERACI√ìN DE ACCESIBILIDAD PARA VIDEOS =====")
    print("(Compatible con est√°ndares UNE 153010 y UNE 153020)")
    print("\nEste programa procesa videos para generar:")
    print("- Subt√≠tulos profesionales (UNE 153010)")  
    print("- Audiodescripci√≥n (UNE 153020)")
    print("- Guion completo minuto a minuto")
    print("- Video final con accesibilidad integrada")
    print("\nSoporta videos de YouTube y archivos locales.\n")
    
    # Solicitar ruta o URL del video
    source = input("Introduce URL de YouTube o ruta al video local: ")
    
    # Solicitar directorio de salida (opcional)
    output_dir = input("Directorio de salida (dejar en blanco para usar 'output/'): ")
    output_dir = output_dir if output_dir.strip() else "output"
    
    try:
        # Inicializar pipeline
        print("\n[1/5] Iniciando pipeline de procesamiento...")
        pipeline = AccessibilityPipeline(source, output_dir)
        
        # Procesar video
        print("[2/5] Analizando video...")
        output_files = pipeline.process_video()
        
        # Mostrar resultados
        print("\n‚úÖ ¬°Procesamiento completado con √©xito!")
        print("\nArchivos generados:")
        
        # Agrupar por categor√≠a
        print("\nüìù GUIONES:")
        if 'full_script' in output_files:
            print(f"  - Guion completo: {output_files['full_script']}")
        if 'audio_description_script' in output_files:
            print(f"  - Guion de audiodescripci√≥n: {output_files['audio_description_script']}")
            
        print("\nüé¨ MEDIOS:")
        if 'video_with_audio_description' in output_files:
            print(f"  - Video accesible: {output_files['video_with_audio_description']}")
        if 'subtitles' in output_files:
            print(f"  - Archivo de subt√≠tulos: {output_files['subtitles']}")
        if 'audio_description' in output_files:
            print(f"  - Audio de descripciones: {output_files['audio_description']}")
        
        # Abrir directorio de salida
        print(f"\nüìÇ Todos los archivos se han guardado en: {os.path.abspath(output_dir)}")
        try:
            if os.name == 'nt':  # Windows
                os.startfile(output_dir)
            elif os.name == 'posix':  # Linux/Mac
                if 'darwin' in sys.platform:  # Mac
                    subprocess.run(['open', output_dir])
                else:  # Linux
                    subprocess.run(['xdg-open', output_dir])
            print("\n‚ñ∂Ô∏è Abriendo directorio de salida...")
        except:
            pass
        
    except Exception as e:
        print(f"\n‚ùå Error durante el procesamiento: {str(e)}")
        # Sugerir soluciones comunes
        if "ffmpeg" in str(e).lower():
            print("\nSugerencia: Aseg√∫rate de tener ffmpeg instalado y en el PATH del sistema.")
            print("Puedes descargarlo desde: https://ffmpeg.org/download.html")
        elif "whisper" in str(e).lower():
            print("\nSugerencia: Verifica que openai-whisper est√© correctamente instalado:")
            print("pip install openai-whisper setuptools-rust")
        elif "vertex" in str(e).lower() or "google" in str(e).lower():
            print("\nSugerencia: Verifica tus credenciales de Google Cloud y variables de entorno.")
            print("Aseg√∫rate de que GOOGLE_APPLICATION_CREDENTIALS est√© configurado correctamente.")