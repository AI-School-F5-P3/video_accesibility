# Proyecto de Audiodescripciones y SubtÃ­tulos


## DescripciÃ³n

Este proyecto desarrolla una plataforma integral para la creaciÃ³n, gestiÃ³n y distribuciÃ³n de audiodescripciones y subtÃ­tulos para contenido audiovisual. Nuestro objetivo es mejorar la accesibilidad del contenido multimedia para personas con discapacidades visuales y auditivas, siguiendo estÃ¡ndares internacionales y ofreciendo herramientas avanzadas asistidas por IA.

## CaracterÃ­sticas Principales

- **TranscripciÃ³n automÃ¡tica de audio** usando Whisper de OpenAI
- **GeneraciÃ³n de audiodescripciones** con asistencia de IA y herramientas de ediciÃ³n manual
- **SÃ­ntesis de voz de alta calidad** con Coqui TTS y Google Cloud TTS
- **DetecciÃ³n automÃ¡tica de escenas** con SceneDetect
- **CreaciÃ³n de subtÃ­tulos** con transcripciÃ³n automÃ¡tica y soporte para SDH (SubtÃ­tulos para Sordos)
- **Procesamiento y anÃ¡lisis de audio** con Librosa
- **API RESTful** para integraciÃ³n con FastAPI
- **Cumplimiento normativo** con estÃ¡ndares internacionales de accesibilidad (WCAG, EBU-TT, etc.)
- **Compatibilidad con mÃºltiples idiomas** a travÃ©s de modelos multilingÃ¼es

##  Inicio RÃ¡pido

### Requisitos Previos

- Python 3.9 o superior
- Docker y Docker Compose
- Componentes multimedia (FFmpeg)
- Servicios Google Cloud (para TTS y procesamiento de IA)
- Cuenta en servicios cloud (opcional para despliegue)

### InstalaciÃ³n

1. Clonar el repositorio:
   ```bash
   git clone https://github.com/tu-organizacion/proyecto-audiodescripciones.git
   cd proyecto-audiodescripciones
   ```

2. Crear y activar un entorno virtual:
   ```bash
   python -m venv venv
   source venv/bin/activate  # En Windows: venv\Scripts\activate
   ```

3. Instalar dependencias:
   ```bash
   pip install -r requirements.txt
   ```

4. Configurar variables de entorno:
   ```bash
   cp .env.example .env
   # Editar .env con tus configuraciones
   ```

5. Iniciar los servicios con Docker:
   ```bash
   docker-compose up -d
   ```

6. Acceder a la aplicaciÃ³n:
   ```
   API: http://localhost:8000
   DocumentaciÃ³n API: http://localhost:8000/docs
   Interfaz web: http://localhost:8000/ui
   ```

## ğŸ§© Arquitectura

El proyecto sigue una arquitectura modular:

```
â”œâ”€â”€ api/                # API FastAPI para todos los endpoints
â”‚   â”œâ”€â”€ endpoints/      # Endpoints especÃ­ficos (audiodesc, subtitle, video)
â”‚   â””â”€â”€ main.py         # ConfiguraciÃ³n principal de la API
â”œâ”€â”€ data/               # Datos y archivos procesados
â”‚   â”œâ”€â”€ audio/          # Archivos de audio extraÃ­dos
â”‚   â”œâ”€â”€ processed/      # Videos procesados con frames y metadatos
â”‚   â”œâ”€â”€ raw/            # Videos originales sin procesar
â”‚   â””â”€â”€ transcripts/    # SubtÃ­tulos generados (.srt)
â”œâ”€â”€ docs/               # DocumentaciÃ³n (incluye estÃ¡ndares UNE153010/UNE153020)
â”œâ”€â”€ front/              # Interfaz web simple con HTML/CSS/JS
â”œâ”€â”€ src/                # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ config/         # ConfiguraciÃ³n y credenciales
â”‚   â”œâ”€â”€ core/           # Funcionalidades principales
â”‚   â”‚   â”œâ”€â”€ audio_processor.py    # Procesamiento de audio
â”‚   â”‚   â”œâ”€â”€ speech_processor.py   # Reconocimiento y sÃ­ntesis de voz
â”‚   â”‚   â”œâ”€â”€ text_processor.py     # Procesamiento de texto
â”‚   â”‚   â””â”€â”€ video_analyzer.py     # AnÃ¡lisis de video y escenas
â”‚   â”œâ”€â”€ models/         # Modelos de datos
â”‚   â”œâ”€â”€ services/       # Servicios de alto nivel
â”‚   â””â”€â”€ utils/          # Utilidades (logging, formateo, validaciÃ³n)
â”œâ”€â”€ tests/              # Tests unitarios e integraciÃ³n
â””â”€â”€ examples/           # Ejemplos de uso
```

##  DocumentaciÃ³n

La documentaciÃ³n del proyecto incluye:

- EstÃ¡ndar UNE153010 - Para subtitulado
- EstÃ¡ndar UNE153020 - Para audiodescripciÃ³n
- DocumentaciÃ³n API automÃ¡tica en (generada por FastAPI):
- [GuÃ­a de ContribuciÃ³n](./CONTRIBUTING.md)
- [CÃ³digo de conducta](./CODE_OF_CONDUCT.md)

## Pruebas

Para ejecutar las pruebas:

```bash
# AsegÃºrate de tener el entorno virtual activado
source env/bin/activate  # En Windows: env\Scripts\activate

# Ejecutar todas las pruebas
pytest

# Ejecutar pruebas especÃ­ficas
pytest tests/test_video_analyzer.py
pytest tests/test_audio_processor.py
pytest tests/test_speech_processor.py
```

##  Roadmap

- **Fase 1 (MVP)** - Funcionalidades bÃ¡sicas de audiodescripciÃ³n y subtitulado
- **Fase 2** - IntegraciÃ³n de modelos de IA avanzados y soporte multilingÃ¼e
- **Fase 3** - Herramientas avanzadas de control de calidad y API para desarrolladores
- **Fase 4** - Funcionalidades colaborativas y marketplace de servicios



## Demos 

- [Demo en vivo](https://drive.google.com/file/d/1NQJxre1EunOqDbzsNwLlu5S1XoMYb13i/view?usp=drive_link)
  


## Equipo

- **Jaanh Yajuri B** - Especialista en IA/ML - [@jyajupy](https://github.com/jyajupy)
- **Iryna Bilokon** - Especialista en IA/ML - [@irynabilokon](https://github.com/irynabilokon)
- **Lisy Velasco** - Especialista en IA/ML - [@lisy29](https://github.com/Lisy29)
- **Leire Martin-Berdinos** - Especialista en IA/ML - [@leimber](https://github.com/leimber)


## Contribuir

Â¡Las contribuciones son bienvenidas! Por favor, lee nuestra [GuÃ­a de ContribuciÃ³n](./CONTRIBUTING.md) antes de enviar un pull request. Sigue nuestro [CÃ³digo de Conducta](./CODE_OF_CONDUCT.md) en todas las interacciones.

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la [Licencia Apache](./LICENSE).

## Agradecimientos

- Scalian por su propuesta y seguimiento del proyecto
- FactorÃ­a F5 por la formaciÃ³n que culmina este proyecto




<p align="center">
  <sub>Hecho con â¤ï¸ para mejorar la accesibilidad audiovisual para todos</sub>
</p>
